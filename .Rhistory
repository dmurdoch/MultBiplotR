Coiner$XINFO$Scaling=ScalingX
Coiner$XINFO$Means = apply(X, 2, mean)
Coiner$XINFO$Medians = apply(X, 2, median)
Coiner$XINFO$Deviations = apply(X, 2, sd)
Coiner$XINFO$Minima = apply(X, 2, min)
Coiner$XINFO$Maxima = apply(X, 2, max)
Coiner$XINFO$P25 = apply(X, 2, quantile)[2, ]
Coiner$XINFO$P75 = apply(X, 2, quantile)[4, ]
Coiner$XINFO$GMean = mean(X)
#Information about Y
Coiner$YINFO$Non_Scaled_Data = Y
Coiner$YINFO$Scaling=ScalingY
Coiner$YINFO$Means = apply(Y, 2, mean)
Coiner$YINFO$Medians = apply(Y, 2, median)
Coiner$YINFO$Deviations = apply(Y, 2, sd)
Coiner$YINFO$Minima = apply(Y, 2, min)
Coiner$YINFO$Maxima = apply(Y, 2, max)
Coiner$YINFO$P25 = apply(Y, 2, quantile)[2, ]
Coiner$YINFO$P75 = apply(Y, 2, quantile)[4, ]
Coiner$YINFO$GMean = mean(Y)
Data = InitialTransform(X, transform = ScalingX)
Data
D=diag(COIN$d[1:dimsol])
D
D^(-0.5)
D %^% 0.5
Di=diag(1/COIN$d[1:dimsol])
Di
D
AXW=X %*% U %*% sqrt(D)
AX
AXW
AXW=X %*% U %*% sqrt(Di)
AXW
U %*% sqrt(D)
V %*% sqrt(D)
X %*% U
Xfit=X %*% U %*% t(U)
Xfit
apply(X^2, 1, sum)
100*sum(Xfit^2)/sum(X^2)
Yfited=Y %*% V %*% t(V)
YFit=100*sum(Yfitted^2)/sum(Y^2)
Xfitted=X %*% U %*% t(U)
XFit=100*sum(Xfitted^2)/sum(X^2)
Yfitted=Y %*% V %*% t(V)
YFit=100*sum(Yfitted^2)/sum(Y^2)
YFit
source('~/Library/Mobile Documents/com~apple~CloudDocs/0 ProgramasR/Paquetes/MultBiplotR/R/summary.ContinuousBiplot.R')
summary(bip)
library(MultBiplotR)
data(Protein)
X=Protein[,3:11]
help("PCA.Biplot")
# JK-Biplot por defecto
bip=PCA.Biplot(X)
summary(bip)
summary(bip, latex=TRUE)
library("xtable", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
summary(bip, latex=TRUE)
library(MultBiplotR)
data(spiders)
x2=Dataframe2BinaryMatrix(spiders)
colnames(x2)=colnames(spiders)
dist=BinaryProximities(x2)
pco=PrincipalCoordinates(dist)
pcobip=ExternalBinaryLogisticBiplot(pco)
plot(pcobip)
pcobip=AddContVars2Biplot(pcobip, as.matrix(SpidersEnv))
plot(pcobip)
help(CCA)
ccabip=CCA(SpidersSp, SpidersEnv)
plot(ccabip)
class(ccabip)
plot(ccabip, mode="s")
help("plot.CCA.sol")
plot(ccabip, mode="s")
plot(ccabip, mode="s", margin=0.1)
library(MultBiplotR)
data(Protein)
X=Protein[,3:11]
# Biplot para Análisis Factorial
fabip=FA.Biplot(X, Extraction="ML", Rotation="oblimin")
plot(fabip, mode="b", margin=0.05, AddArrow=TRUE)
summary(fabip)
data(Chemical)
x= Chemical[37:144,5:9]
weeks=as.factor(as.numeric(Chemical$WEEKS[37:144]))
levels(weeks)=c("W2" , "W3", "W4")
X=Convert2ThreeWay(x,weeks, columns=FALSE)
Groups=Chemical$Treatment[1:36]
canstbip=CanonicalStatisBiplot(X, Groups, SameVar = TRUE)
plot(canstbip, mode="s", PlotVars=TRUE, ShowBox=TRUE)
plot(canstbip, mode="b", PlotVars=TRUE, ShowBox=TRUE)
plot(canstbip, mode="b", PlotVars=TRUE, ShowBox=TRUE, margin=0.1 )
data(Chemical)
x= Chemical[,5:16]
X=Convert2ThreeWay(x,Chemical$WEEKS, columns=FALSE)
stbip=StatisBiplot(X)
Groups=Chemical$Treatment[1:36]
canstbip=CanonicalStatisBiplot(X, Groups)
plot(stbip)
fabip=FA.Biplot(X, Extraction="ML", Rotation="oblimin")
plot(fabip, mode="b", margin=0.05, AddArrow=TRUE)
summary(fabip)
data(Chemical)
x= Chemical[,5:16]
X=Convert2ThreeWay(x,Chemical$WEEKS, columns=FALSE)
stbip=StatisBiplot(X)
Groups=Chemical$Treatment[1:36]
canstbip=CanonicalStatisBiplot(X, Groups)
X
library(cluster)
library(tm)
library(LSAfun)
source_dir="~/Dropbox/0 Sentiment Analysis/Discursos/txt"
doc_source=DirSource(source_dir)
raw_corpus <- VCorpus(doc_source, readerControl=list(language='es'))
stoplist=c(stopwords("es"), "política", "social", "gobierno", "españa", "español",
"señorías", "acuerdo", "año", "hemo", "hemos", "señoría", "señorías",
"país", "gobierno", "año", "han", "aún", "ustedes", "consiguiente")
tdm <- TermDocumentMatrix(raw_corpus,
control=list(removePunctuation = TRUE,
removeNumbers = TRUE,
tolower = TRUE,
stopwords = stoplist,
stemming = TRUE, # snowball stemmer
weighting = function(x) weightTfIdf(x, normalize = FALSE), # Weight with tf-idf
bounds=list(global=c(5,Inf))))
tdm
inspect(tdm[10:20,1:6])
findFreqTerms(tdm, 15)
myLSAspace <- lsa(tdm, dims=dimcalc_share())
dim(myLSAspace$tk) # Check how many rows/columns the tk matrix has
myLSAtk = t(myLSAspace$sk * t(myLSAspace$tk))
plot_neighbors("corrupcion",n=20,tvectors= myLSAtk[,1:5]) # Use only the first 70 dimensions
source_dir="~/Dropbox/0 Sentiment Analysis/Discursos/txt"
doc_source=DirSource(source_dir)
raw_corpus <- VCorpus(doc_source, readerControl=list(language='es'))
stoplist=c(stopwords("es"), "política", "social", "gobierno", "españa", "español",
"señorías", "acuerdo", "año", "hemo", "hemos", "señoría", "señorías",
"país", "gobierno", "año", "han", "aún", "ustedes", "consiguiente")
tdm2 <- TermDocumentMatrix(raw_corpus,
control=list(removePunctuation = TRUE,
removeNumbers = TRUE,
tolower = TRUE,
stopwords = stoplist,
stemming = TRUE, # snowball stemmer
weighting = function(x)  weightTf(x), # Weight with tf-idf
bounds=list(global=c(5,Inf))))
tdm2
m2 = as.matrix(tdm2)
colnames(m2)<-c("Az96", "Az00", "Cal81", "Go82", "Go86", "Go89", "Go93", "Ra11", "Ra16-2", "Ra16", "Sa18", "Su79", "Za04", "Za08")
biptdm2=CA(m2, dim=3)
plot(biptdm2, MinQualityInds=0.7, margin=0.1)
colsum=apply(m2,2,sum)
m3=t(m2 %*% diag(1/colsum))
rownames(m3)<-c("Az96", "Az00", "Cal81", "Go82", "Go86", "Go89", "Go93", "Ra11", "Ra16-2", "Ra16", "Sa18", "Su79", "Za04", "Za08")
biptdm3=PCA.Biplot(m3, Scaling = 5)
plot(biptdm3, MinQualityVars=0.7, mode="p", margin=0.1)
m = as.matrix(tdm2)
v = sort(rowSums(m), decreasing = TRUE)
set.seed(4363)
wordcloud(names(v),v, min.freq = 0 ,max.words=200, colors=brewer.pal(6,"Dark2"),random.order=FALSE)
library(wordcloud)
library(MultBiplot)
library(MultBiplotR)
wordcloud(names(v),v, min.freq = 0 ,max.words=200, colors=brewer.pal(6,"Dark2"),random.order=FALSE)
source_dir="~/Dropbox/0 Sentiment Analysis/Discursos/txt"
doc_source=DirSource(source_dir)
raw_corpus <- VCorpus(doc_source, readerControl=list(language='es'))
stoplist=c(stopwords("es"), "política", "social", "gobierno", "españa", "español",
"señorías", "acuerdo", "año", "hemo", "hemos", "señoría", "señorías",
"país", "gobierno", "año", "han", "aún", "ustedes", "consiguiente")
tdm2 <- TermDocumentMatrix(raw_corpus,
control=list(removePunctuation = TRUE,
removeNumbers = TRUE,
tolower = TRUE,
stopwords = stoplist,
stemming = TRUE, # snowball stemmer
weighting = function(x)  weightTf(x), # Weight with tf-idf
bounds=list(global=c(5,Inf))))
tdm2
m2 = as.matrix(tdm2)
colnames(m2)<-c("Az96", "Az00", "Cal81", "Go82", "Go86", "Go89", "Go93", "Ra11", "Ra16-2", "Ra16", "Sa18", "Su79", "Za04", "Za08")
biptdm2=CA(m2, dim=3)
plot(biptdm2, MinQualityInds=0.7, margin=0.1)
install.packages('sharpshootR', dep=TRUE)
install.packages('e1071', dep=TRUE)
devtools::install_github("ncss-tech/sharpshootR", dependencies=FALSE, upgrade_dependencies=FALSE)
library(soilDB)
library(sharpshootR)
x <- fetchNASIS()
x
idx <- grep('Nedsgulch', x$taxonname, ignore.case = TRUE)
nedsgulch <- x[idx, ]
h <- horizons(nedsgulch)
idx <- grep('Bt1', h$hzname)
z <- h$clay[idx]
percentileDemo(z, hist.breaks=30, xlab='Field Described Percent Clay', main='NASIS: Nedsgulch, Bt1 horizons')
horizons
h <- horizons(nedsgulch)
idx <- grep('Nedsgulch', x$taxonname, ignore.case = TRUE)
nedsgulch <- x[idx, ]
nedsgulch
x
fetchNASIS
x <- fetchNASIS()
x <- rnorm(1000, 100, 15)
e <- ecdf(x)
e
p <- sample(x, 1)
p.lab <- paste0(round(p), ' tons/ha\n', round(e(p) * 100), 'th percentile of all regions')
par(mar=c(6,1,4,1))
hist(x, axes=FALSE, xlab='', ylab='', main='Carbon Stocks of all Regions', breaks=50, col = grey(0.9), border = grey(0.85))
axis(1, at=pretty(x, n = 10), cex.axis=0.75)
points(p, 0, pch=21, bg='RoyalBlue', col='black', cex=2)
axis(1, at=p, labels = p.lab, cex.axis=0.75, line=2.5, lwd=2, tcl=2, col = 'RoyalBlue')
round(7.8)
is.int <- function(x){
if (round(x)==x)
return(TRUE)
else
return(FALSE)
}
is.int(2)
is.int(2.01)
ceiling(x)
ceiling(2)
trunc(2)
trunc(2.8)
ceiling(2.8)
help(sort)
x
sample=x
sample=sort(sample)
n=length(sample)
sample
n
r=p*(n+1)
r
p=0.5
n
r=p*(n+1)
r
is.int <- function(x){
if (round(x)==x)
return(TRUE)
else
return(FALSE)
}
is.int(r)
(sample[trunc(r)]+sample[ceiling(r)])/2
median(sample)
datos=c(0.49, 0.59, 0.86, 1.01, 1.24, 1.25, 1.81, 2.01, 2.29, 2.66, 2.82, 2.85, 3, 3.27, 4.44, 5.14, 5.53, 5.6, 6.06, 6.29)
percentile(datos, p=0.5)
percentile <- function(sample, p=0.5){
sample=sort(sample)
n=length(sample)
r=p*(n+1)
if (is.int(r)) per=sample[r]
else
per=(sample[trunc(r)]+sample[ceiling(r)])/2
}
datos=c(0.49, 0.59, 0.86, 1.01, 1.24, 1.25, 1.81, 2.01, 2.29, 2.66, 2.82, 2.85, 3, 3.27, 4.44, 5.14, 5.53, 5.6, 6.06, 6.29)
datos=c(0.49, 0.59, 0.86, 1.01, 1.24, 1.25, 1.81, 2.01, 2.29, 2.66, 2.82, 2.85, 3, 3.27, 4.44, 5.14, 5.53, 5.6, 6.06, 6.29)
datos=c(0.49, 0.59, 0.86, 1.01, 1.24, 1.25, 1.81, 2.01, 2.29, 2.66, 2.82, 2.85, 3, 3.27, 4.44, 5.14, 5.53, 5.6, 6.06, 6.29)
percentile(datos, p=0.5)
return(per)
percentile <- function(sample, p=0.5){
sample=sort(sample)
n=length(sample)
r=p*(n+1)
if (is.int(r)) per=sample[r]
else
per=(sample[trunc(r)]+sample[ceiling(r)])/2
return(per)
}
percentile(datos, p=0.5)
help("binomial")
help("binomial")
help("rnorm")
dbinom(5, 10, 0.5)
size=10
tabla=rep(0:size)
tabla
p=0.5
binomtable <- function(size, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i]=dbinom(i, size, p)
}
binomtable <- function(size, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=0:size
return(table)
}
binomtable(10, 0.3)
binomtable(10, 0.3)
binomtable <- function(size, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=0:size
return(table)
}
binomtable
binomtable(10, 0.3)
binomialtable <- function(size, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=0:size
return(table)
}
binomialtable
binomialtable(10, 0.3)
binomialtable(size=10, p=0.3)
percentile <- function(sample, p=0.5){
sample=sort(sample)
n=length(sample)
r=p*(n+1)
if (is.int(r)) per=sample[r]
else
per=(sample[trunc(r)]+sample[ceiling(r)])/2
return(per)
}
datos=c(0.49, 0.59, 0.86, 1.01, 1.24, 1.25, 1.81, 2.01, 2.29, 2.66, 2.82, 2.85, 3, 3.27, 4.44, 5.14, 5.53, 5.6, 6.06, 6.29)
percentile(datos, p=0.5)
dbinom(5, 10, 0.5)
binomialtable
binomialtable <- function(size=10, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=0:size
return(table)
}
binomialtable()
binomialtable <- function(size=10, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=0:size
return(tabla)
}
binomialtable(size=10, p=0.3)
tabla=binomialtable(size=10, p=0.3)
who(tabla=max(tabla))
help(max)
help(who)
??who
help("which.max")
which.max(x)
which.max(tabla)
tabla
dbinom(10, 10, 0.5)
tabla=binomialtable(size=10, p=0.5)
tabla
which.max(tabla)
dbinom(10, 10, 0.5)
help(dbinom)
binomialtable <- function(size=10, p=0.5){
tabla=rep(0:size)
for (i in 0:size)
tabla[i+1]=dbinom(i, size, p)
names(tabla)=0:size
return(tabla)
}
tabla=binomialtable(size=10, p=0.5)
tabla
which.max(tabla)
x <- c(1:4, 0:5, 11)
which.min(x)
which.max(x)
tabla=binomialtable(size=10, p=0.5)
tabla
max(tabla)
tabla=binomialtable(size=20, p=0.5)
tabla
sort(tabla)
tabla=binomialtable(size=20, p=0.5)
tabla
binomialtable <- function(size=10, p=0.5){
tabla=rep(0:size)
for (i in 1:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=1:size
return(tabla)
}
tabla=binomialtable(size=20, p=0.5)
tabla
binomialtable <- function(size=10, p=0.5){
tabla=rep(1:size)
for (i in 1:size)
tabla[i]=dbinom(i, size, p)
names(tabla)=1:size
return(tabla)
}
tabla=binomialtable(size=20, p=0.5)
tabla
tabla=sort(tabla)
tabla=binomialtable(size=20, p=0.5)
tabla=sort(tabla, decreasing = TRUE)
tabla
tabla=cumsum(tabla)
tabla
bipXY=PCA.Biplot(XY, alpha=0)
plot(bipXY, ColorVar=c(rep("blue", 9), rep("green", 7)))
library(MultBiplotR)
SSI <- read.table("~/Dropbox/Referee Co-Tucker/Datos.txt", header = TRUE)
SSI$Year == "a2006"
SSI2D=SSI[SSI$Year == "a2006",3:23]
dim(SSI2D)
rownames(SSI2D)=as.character(SSI$Country[SSI$Year == "a2006"])
SSIHuman2D=SSI2D[,1:9]
SSIEnvir2D=SSI2D[,10:16]
SSIEcon2D=SSI2D[,17:21]
XY=cbind(X,Y)
bipXY=PCA.Biplot(XY, alpha=0)
plot(bipXY, ColorVar=c(rep("blue", 9), rep("green", 7)))
X=InitialTransform(SSIHuman2D, transform = 5)$X
Y=InitialTransform(SSIEnvir2D, transform = 5)$X
SVDX=svd(X)
SVDY=svd(Y)
AX=SVDX$u[,1:dim]%*%diag(SVDX$d[1:dim])
BX=SVDX$v[,1:dim]
AY=SVDY$u[,1:dim]%*%diag(SVDY$d[1:dim])
BY=SVDY$v[,1:dim]
cor(AX,AY)
COI=t(AX) %*% AY
SVDCOI=svd(COI)
COI2=BX %*% t(BY)
SVDCOI2=svd(COI2, nu=2, nv=2)
dudi1 <- dudi.pca(X, scale = TRUE, scan = FALSE, nf = 3)
dudi2 <- dudi.pca(Y, scale = FALSE, scan = FALSE, nf = 2)
coin1 <- coinertia(dudi1,dudi2, scan = FALSE, nf = 2)
coin1
plot(coin1)
dudi1 <- dudi.pca(X, scale = TRUE, scan = FALSE, nf = 3)
library(ade4)
dudi1 <- dudi.pca(X, scale = TRUE, scan = FALSE, nf = 3)
dudi2 <- dudi.pca(Y, scale = FALSE, scan = FALSE, nf = 2)
coin1 <- coinertia(dudi1,dudi2, scan = FALSE, nf = 2)
coin1
plot(coin1)
AX
BX
AY
BY
coin1 <- coinertia(dudi1,dudi2, scan = FALSE, nf = 2)
coin1
plot(coin1)
SSIHuman2D
XY=cbind(SSIHuman2D,SSIEnvir2D)
bipXY=PCA.Biplot(XY, alpha=0)
plot(bipXY, ColorVar=c(rep("blue", 9), rep("green", 7)))
bipHum=PCA.Biplot(SSIHuman2D, alpha=0)
library(MultBiplotR)
SSI <- read.table("~/Dropbox/Referee Co-Tucker/Datos.txt", header = TRUE)
SSI$Year == "a2006"
SSI2D=SSI[SSI$Year == "a2006",3:23]
dim(SSI2D)
rownames(SSI2D)=as.character(SSI$Country[SSI$Year == "a2006"])
SSIHuman2D=SSI2D[,1:9]
SSIEnvir2D=SSI2D[,10:16]
SSIEcon2D=SSI2D[,17:21]
# Joint Biplot of Human and Environmental Indicators
XY=cbind(SSIHuman2D,SSIEnvir2D)
bipXY=PCA.Biplot(XY, alpha=0)
plot(bipXY, ColorVar=c(rep("blue", 9), rep("green", 7)))
plot(bipXY, ColorVar=c(rep("blue", 9), rep("green", 7)), AbbreviateLabels=TRUE)
ggplot.ContinuousBiplot(bipXY)
library("MultBiplotRGUI", lib.loc="~/Library/R/3.4/library")
ggplot.ContinuousBiplot(bipXY)
install.packages("ggrepel")
library("ggrepel", lib.loc="~/Library/R/3.4/library")
ggplot.ContinuousBiplot(bipXY)
ggplot.ContinuousBiplot(bipXY, VarLabelAbbrev=TRUE, IndLabelAbbrev=TRUE, CexInd=0.7)
ggplot.ContinuousBiplot(bipXY, VarLabelAbbrev=TRUE, IndLabelAbbrev=TRUE, CexInd=0.5)
ggplot.ContinuousBiplot(bipXY, VarLabelAbbrev=TRUE, IndLabelAbbrev=TRUE, CexInd=0.5,  ColorVar=c(rep("blue", 9), rep("green", 7)))
ggplot.ContinuousBiplot(bipXY, VarLabelAbbrev=TRUE, IndLabelAbbrev=TRUE, CexInd=0.3,  ColorVar=c(rep("blue", 9), rep("green", 7)))
# Ordination of Human and Evironment Projected
bipHum=PCA.Biplot(SSIHuman2D, alpha=0)
plot(bipHum)
plot(bipHum, AbbreviateLabels=TRUE)
bipHum=AddContVars2Biplot(bipHum,  SSIEnvir2D)
plot(bipHum, AbbreviateLabels=TRUE)
summary(bipHum)
attributes(bipHum)
bipHum$ContSupVarsBiplot
summary(bipHum$ContSupVarsBiplot)
cbind
bipHum2=AddContVars2Biplot(bipHum,  cbind(SSIEnvir2D, SSIEcon2D))
plot(bipHum2, AbbreviateLabels=TRUE)
rep("blue", p)
p=4
rep("blue", p)
library(MultBiplotR)
plot(bipHum2, AbbreviateLabels=TRUE, ColorSupContVars=c(rep("blue",7), rep("green",5)))
library(MultBiplotR)
plot(bipHum2, AbbreviateLabels=TRUE, ColorSupContVars=c(rep("blue",7), rep("green",5)))
bipHum2=AddContVars2Biplot(bipHum,  cbind(SSIEnvir2D, SSIEcon2D))
plot(bipHum2, AbbreviateLabels=TRUE, ColorSupContVars=c(rep("blue",7), rep("green",5)))
library(MultBiplotR)
plot(bipXY, ColorVar=c(rep("blue", 9), rep("green", 7)), AbbreviateLabels=TRUE)
There were 48 warnings (use
warnings()
library(MultBiplotR)
plot(bipHum2, AbbreviateLabels=TRUE, ColorSupContVars=c(rep("blue",7), rep("green",5)))
